{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ab375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import zscore\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee4702",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb79327",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/irenewalken/Documents/GitHub/Airline-Passenger-Satisfaction-Machine_learning-/Data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/irenewalken/Documents/GitHub/Airline-Passenger-Satisfaction-Machine_learning-/Data/test.csv\")\n",
    "data = pd.concat([train, test])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa69c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab0d7c",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6b8e7",
   "metadata": {},
   "source": [
    "**Drop unused columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d4807",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 0\"], axis = 1)\n",
    "data = data.drop([\"id\"], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531a5d1",
   "metadata": {},
   "source": [
    "**Check the data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9381b4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a50881",
   "metadata": {},
   "source": [
    "**Check if we have NaN values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ed098",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e2b82",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916ff79",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094cf79",
   "metadata": {},
   "source": [
    "**>>>>>We have 393 rows with Nan value and as Nan value is less than 1% of data, the better way is drop this rows, but then when we start the EDA and check corralation between columns, we can see that \"Departure Delay in Minutes\" and \"Arrival Delay in Minutes\" have extremely hight corralation, so we will need to drop one of column. Evensually I droped \"Arrival Delay in Minutes\" without dropping rows with Nan vulue<<<<<**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00115639",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data.dropna() - if we wanna drop rows with the nan value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafac1fe",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02611e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_numerical = data.select_dtypes(include=np.number, exclude=np.object)#get numerical data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6022fb",
   "metadata": {},
   "source": [
    "## Correlation map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2981f8a",
   "metadata": {},
   "source": [
    "**Make a heat map for seeing the correlation between columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d354cf4",
   "metadata": {},
   "source": [
    "We can see that Arrival Delay in Minutes and Departure Delay in Minutes have very strong correlation, so we need to drop one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb914e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = data_numerical.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(16, 12))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce3741",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop([\"Arrival Delay in Minutes\"],axis = 1)\n",
    "data.to_csv('/Users/irenewalken/Documents/GitHub/Airline-Passenger-Satisfaction-Machine_learning-/Airline-Passenger-Satisfaction-Machine_learning.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37b873",
   "metadata": {},
   "source": [
    "## Remove the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d40a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e803b83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "\n",
    "plt.boxplot(data[\"Flight Distance\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3805a20",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q1 = np.percentile(data[\"Flight Distance\"], 25,\n",
    "                   interpolation = 'midpoint')\n",
    " \n",
    "Q3 = np.percentile(data[\"Flight Distance\"], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Upper bound\n",
    "upper = np.where(data[\"Flight Distance\"] >= (Q3+1.5*IQR))\n",
    "print(upper)\n",
    "\n",
    "# Lower bound\n",
    "lower = np.where(data[\"Flight Distance\"] <= (Q1-1.5*IQR))\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52462190",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data[\"Flight Distance\"]< Q3+1.5*IQR]   # delete Upper bound outliers (we don't have lower bound, so we will delete just upper bound)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9dbfe3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138efbd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "\n",
    "plt.boxplot(data[\"Departure Delay in Minutes\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ab967",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q1 = np.percentile(data[\"Departure Delay in Minutes\"], 25,\n",
    "                   interpolation = 'midpoint')\n",
    " \n",
    "Q3 = np.percentile(data[\"Departure Delay in Minutes\"], 75,\n",
    "                   interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Upper bound\n",
    "upper = np.where(data[\"Departure Delay in Minutes\"] >= (Q3+1.5*IQR))\n",
    "print(upper)\n",
    "\n",
    "# Lower bound\n",
    "lower = np.where(data[\"Departure Delay in Minutes\"] <= (Q1-1.5*IQR))\n",
    "print(lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cba3d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data[\"Departure Delay in Minutes\"]< Q3+1.5*IQR]   # delete Upper bound outliers (we don't have lower bound, so we will delete just upper bound)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd1d6e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f052480",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical = data.select_dtypes(include=np.object, exclude=np.number)#get categorical data\n",
    "data_numerical = data.select_dtypes(include=np.number, exclude=np.object)\n",
    "data_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8dc2a",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d137d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical[\"Class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632b0c7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical[\"Class\"] = data_categorical[\"Class\"].replace([\"Business\", \"Eco Plus\", \"Eco\"], [3,2,1])\n",
    "data_categorical[\"satisfaction\"] = data_categorical[\"satisfaction\"].replace([\"neutral or dissatisfied\", \"satisfied\"], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1b0ab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical[\"Class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4692e7d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef390f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_categorical[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a1458",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_categorical.drop([\"Class\", \"satisfaction\"],axis =1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf824f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features=pd.get_dummies(X, drop_first=True).astype(np.int64) # One hot\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84b237",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pd.concat([data_numerical, X_features], axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c597a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total[\"Class\"] = data_categorical[\"Class\"]\n",
    "total[\"satisfaction\"] = data_categorical[\"satisfaction\"]\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b11b71",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316d409",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = total[\"satisfaction\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ce290",
   "metadata": {},
   "source": [
    "# Change imbalance data to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76918e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "satisfaction_0 = total[total[\"satisfaction\"] == 0]\n",
    "satisfaction_1 = total[total[\"satisfaction\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db0db9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total[\"satisfaction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5661d6",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08129d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(satisfaction_0.shape)\n",
    "print(satisfaction_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d33f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "satisfaction_0_down = satisfaction_0.sample(len(satisfaction_1))\n",
    "print(satisfaction_0_down.shape)\n",
    "print(satisfaction_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54572ab2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([satisfaction_0_down,satisfaction_1 ], axis = 0)\n",
    "#shuffling the data\n",
    "data = data.sample(frac=1)\n",
    "data[\"satisfaction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7c9ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531d272",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e82d04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop([\"satisfaction\"], axis = 1)\n",
    "y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60090787",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=24)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=14)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_train_dt = model.predict(X_train)\n",
    "y_pred_test_dt = model.predict(X_test)\n",
    "\n",
    "\n",
    "performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_dt),\n",
    "                                         precision_score(y_train, y_pred_train_dt),\n",
    "                                         recall_score(y_train, y_pred_train_dt)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_dt),\n",
    "                                        precision_score(y_test, y_pred_test_dt),\n",
    "                                        recall_score(y_test, y_pred_test_dt)]})\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model,X_train,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model,X_test,y_test,ax=ax[1],values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8888107",
   "metadata": {},
   "source": [
    "#### Features Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667fd8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_ \n",
    "sorted_idx = np.argsort(feature_importance) # Sort index on feature importance\n",
    "fig = plt.figure(figsize=(20, 15)) # Set plot size (denoted in inches)\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\n",
    "\n",
    "plt.xlabel(\"Feature importance\") # Add x axis\n",
    "plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725e626",
   "metadata": {},
   "source": [
    "### Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c6951",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop([\"satisfaction\"], axis = 1)\n",
    "y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296265bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "model4 = RandomForestClassifier(max_depth=26,min_samples_leaf=20,max_features=None,n_estimators=100,\n",
    "                             bootstrap=True,oob_score=True, random_state=0)\n",
    "model4.fit(X_train, y_train)\n",
    "print(\"Accuracy of train: \",model4.score(X_train, y_train))\n",
    "print(\"Accuracy of test: \",model4.score(X_test, y_test))\n",
    "\n",
    "model4 = RandomForestClassifier(max_depth=26,min_samples_leaf=20,max_features=None,n_estimators=100,\n",
    "                         bootstrap=True,oob_score=True, random_state=0)\n",
    "cross_val_scores = cross_val_score(model4, X_train, y_train, cv=5)\n",
    "cross_val_scores_test = cross_val_score(model4, X_test, y_test, cv=5)\n",
    "print(cross_val_scores)\n",
    "print(cross_val_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50b6b9",
   "metadata": {},
   "source": [
    "#### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77098958",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "model4 = RandomForestClassifier(max_depth=26,min_samples_leaf=20,max_features=None,n_estimators=100,\n",
    "                             bootstrap=True,oob_score=True, random_state=0)\n",
    "selector = RFE(model4, n_features_to_select= 3, step = 1, verbose = 1) # Step is how many features to add or drop everytime\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "kept_features = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "kept_features = list(X_train.iloc[:,kept_features].columns)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_test  = selector.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=kept_features)\n",
    "X_test  = pd.DataFrame(X_test, columns=kept_features)\n",
    "\n",
    "print(\"Final selected features: \")\n",
    "display(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7847f6b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4=RandomForestClassifier(max_depth=26,min_samples_leaf=20,max_features=None,n_estimators=100,\n",
    "                             bootstrap=True,oob_score=True, random_state=0)\n",
    "model4.fit(X_train, y_train)\n",
    "print(f\"{model4.__class__.__name__}: Train -> {model4.score(X_train, y_train)}, Test -> {model4.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137f970",
   "metadata": {},
   "source": [
    "**>>>>>>>>>>The result is worse than with all features<<<<<<<<<<<<**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19a77c",
   "metadata": {},
   "source": [
    "### Random Forest Hyper Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bc33a",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f0b72",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100,500],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt']\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a85853",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ada08c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bb831",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_ #To check the best set of parameters returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10563261",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88d9a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0, max_features='sqrt', \n",
    "                             min_samples_leaf=1, min_samples_split=2, n_estimators=500)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "cross_val_scores_test = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print(np.mean(cross_val_scores))\n",
    "print(np.mean(cross_val_scores_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6471d1",
   "metadata": {},
   "source": [
    "**>>>>>>>>>>>> With Random Forest Hyper Parameter Tunning we have the best test accuracy <<<<<<<<<<**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104656c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad9cfb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop([\"satisfaction\"], axis = 1)\n",
    "y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc714eb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.20,random_state=123)\n",
    "\n",
    "model2 = LogisticRegression() \n",
    "\n",
    "trans = PowerTransformer()\n",
    "\n",
    "trans.fit(X_train)\n",
    "\n",
    "X_train_mod = trans.transform(X_train)\n",
    "X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "model2.fit(X_train_mod, y_train)\n",
    "\n",
    "y_pred_train_log = model2.predict(X_train_mod)\n",
    "y_pred_test_log = model2.predict(X_test_mod)\n",
    "\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log),\n",
    "                                         recall_score(y_train, y_pred_train_log)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log),\n",
    "                                        recall_score(y_test, y_pred_test_log)]})\n",
    "\n",
    "display(performance_log)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model2,X_train,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model2,X_test,y_test,ax=ax[1],values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc906cf",
   "metadata": {},
   "source": [
    "#### Features Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a8e3d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': model2.coef_[0]\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a3942",
   "metadata": {},
   "source": [
    "### Knn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1df58",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop([\"satisfaction\"], axis = 1)\n",
    "y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0050a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.20,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f099c24",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d623f3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler().fit(X_train)   ##. finding the parameters ( mean, variance from the training set )\n",
    "\n",
    "X_train_scaled=std_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1054e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb035d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled=std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d3ff9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train_scaled)\n",
    "print(\"--------\")\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774690d4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "model3 = KNeighborsClassifier()\n",
    "model3.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred_train = model3.predict(X_train_scaled)\n",
    "y_pred_test = model3.predict(X_test_scaled)\n",
    "\n",
    "performance = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "\n",
    "display(performance)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model3,X_train_scaled,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "plot_confusion_matrix(model3,X_test_scaled,y_test,ax=ax[1], values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f2666",
   "metadata": {},
   "source": [
    "### Models Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430b0ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_pipeline = [model,model4, model2, model3]\n",
    "model_names = ['Decision Tree Classifier', 'Random forest Classifier','Logistic Regression', 'KNN Classifier']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05908dc4",
   "metadata": {},
   "source": [
    "## Upsampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e1de5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7f156",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = total\n",
    "X = data.drop([\"satisfaction\"], axis = 1)\n",
    "y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307025d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da531a7c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dd2b1",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65449e3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_sm\n",
    "X = X_sm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "model= DecisionTreeClassifier(max_depth=14)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model,X_train,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model,X_test,y_test,ax=ax[1],values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5e193",
   "metadata": {},
   "source": [
    "### Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaad66e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_sm\n",
    "X = X_sm\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "model4 = RandomForestClassifier(max_depth=30,min_samples_leaf=20,max_features=None,n_estimators=250,\n",
    "                             bootstrap=True,oob_score=True, random_state=0)\n",
    "model4.fit(X_train, y_train)\n",
    "print(\"Accuracy of train: \",model4.score(X_train, y_train))\n",
    "print(\"Accuracy of test: \",model4.score(X_test, y_test))\n",
    "\n",
    "model4 = RandomForestClassifier(max_depth=30,min_samples_leaf=20,max_features=None,n_estimators=250,\n",
    "                         bootstrap=True,oob_score=True, random_state=0)\n",
    "cross_val_scores = cross_val_score(model4, X_train, y_train, cv=5)\n",
    "cross_val_scores_test = cross_val_score(model4, X_test, y_test, cv=5)\n",
    "print(cross_val_scores)\n",
    "print(cross_val_scores_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d590f42",
   "metadata": {},
   "source": [
    "### Random Forest Hyper Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470d95f",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd38186",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100,500],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt']\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3946cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ec28a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd4618",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd018c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408dd548",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0, max_features='sqrt', \n",
    "                             min_samples_leaf=1, min_samples_split=2, n_estimators=500)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "cross_val_scores_test = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "print(np.mean(cross_val_scores))\n",
    "print(np.mean(cross_val_scores_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9a79b",
   "metadata": {},
   "source": [
    "**>>>>>>>>>>>> With Random Forest Hyper Parameter Tunning we have the best test accuracy <<<<<<<<<<**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f0095",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d390073",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_sm\n",
    "X = X_sm\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.20,random_state=123)\n",
    "\n",
    "model2 = LogisticRegression() \n",
    "\n",
    "trans = PowerTransformer()\n",
    "\n",
    "trans.fit(X_train)\n",
    "\n",
    "X_train_mod = trans.transform(X_train)\n",
    "X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "model2.fit(X_train_mod, y_train)\n",
    "\n",
    "y_pred_train_log = model2.predict(X_train_mod)\n",
    "y_pred_test_log = model2.predict(X_test_mod)\n",
    "\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log),\n",
    "                                         recall_score(y_train, y_pred_train_log)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log),\n",
    "                                        recall_score(y_test, y_pred_test_log)]})\n",
    "\n",
    "display(performance_log)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model2,X_train,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model2,X_test,y_test,ax=ax[1],values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3c7c7",
   "metadata": {},
   "source": [
    "### Knn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f214439",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_sm\n",
    "X = X_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049a4db",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.20,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee2062",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661ea54",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler().fit(X_train)  \n",
    "\n",
    "X_train_scaled=std_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7850e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa62fc8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled=std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0600ab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train_scaled)\n",
    "print(\"--------\")\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70570f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = KNeighborsClassifier()\n",
    "model3.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred_train = model3.predict(X_train_scaled)\n",
    "y_pred_test = model3.predict(X_test_scaled)\n",
    "\n",
    "performance = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "\n",
    "display(performance)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model3,X_train_scaled,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "plot_confusion_matrix(model3,X_test_scaled,y_test,ax=ax[1], values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27ad40",
   "metadata": {},
   "source": [
    "### Models Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0ad92",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_pipeline = [model,model4, model2, model3]\n",
    "model_names = ['Decision Tree Classifier', 'Random forest Classifier','Logistic Regression', 'KNN Classifier']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713f69a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
